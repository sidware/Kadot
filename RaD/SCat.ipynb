{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCat Research and Developement\n",
    "\n",
    "The goal of this notebook is to use a recurrent neural network (GRU or LSTM) to learn to extract keyword in a text. This model will be used to extract arguments in a natural language request.\n",
    "\n",
    "Each word will be submitted to a recurrent neural network unit, each unit take a word vector as the input and return some feature about the word being an \"argument\", here a city. These feature will be send to a single neuron that will tranform them into a probability.\n",
    "\n",
    "To achieve this, the text input has to be tokenized and each word as to be transformed into a vector.\n",
    "\n",
    "Usually, the word vector need to be calculated using something like GloVe or Word2Vec butfor simplicity reasons we will use a simple 1-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = lambda text: text.split()\n",
    "\n",
    "def vectorizer(tokens):\n",
    "    vocabulary = list(set(tokens))\n",
    "    embedding = dict()\n",
    "    \n",
    "    for word_index, word in enumerate(vocabulary):\n",
    "        word_vec = torch.zeros(len(vocabulary))\n",
    "        word_vec[word_index] = 1\n",
    "        embedding[word] = word_vec\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the model, I will use a simple GRU cell as the encoder and a raw non-recurrent layer activated by softmax as the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class SCatCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SCatCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.encoder = nn.GRUCell(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        next_hidden_state = self.encoder(input, hidden)\n",
    "        output = self.decoder(next_hidden_state.view(self.hidden_size))\n",
    "        \n",
    "        return next_hidden_state, output\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to prepare a simple dataset and train the model !\n",
    "\n",
    "The dataset is a simple collection of only six weather question, the goal is for the network to identify the city in the sentence like in a supervised classifcation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [\n",
    "    \"What is the weather like in Paris ?\",\n",
    "    \"What kind of weather will it do in London ?\",\n",
    "    \"Give me the weather forecast in Berlin please .\",\n",
    "    \"Tell me the forecast in New York !\",\n",
    "    \"Give me the weather in San Francisco ...\",\n",
    "    \"I want the forecast in Dublin .\"\n",
    "]\n",
    "train_y = [\n",
    "    ('Paris'),\n",
    "    ('London'),\n",
    "    ('Berlin'),\n",
    "    ('New', 'York'),\n",
    "    ('San', 'Francisco'),\n",
    "    ('Dublin')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train the model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 0.0137\n",
      "Epoch 50 - Loss: 0.0006\n",
      "Epoch 100 - Loss: 0.0005\n",
      "Epoch 150 - Loss: 0.0003\n",
      "Epoch 200 - Loss: 0.0002\n",
      "Epoch 250 - Loss: 0.0001\n",
      "Epoch 300 - Loss: 0.0\n",
      "Epoch 350 - Loss: 0.0\n",
      "Epoch 400 - Loss: 0.0\n",
      "Epoch 450 - Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_epoch = 500\n",
    "\n",
    "embeddings = vectorizer(tokenizer(' '.join(train_x + ['Los', 'Angeles']))) # add a city not in the training set for testing\n",
    "\n",
    "model = SCatCell(len(embeddings), 10, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for epoch in range(n_epoch):    \n",
    "    for s_x, s_y in zip([tokenizer(t) for t in train_x], train_y):\n",
    "        hidden_state = model.init_hidden()\n",
    "        \n",
    "        ys = Variable(torch.FloatTensor([0]))\n",
    "        preds = Variable(torch.FloatTensor([0]), requires_grad=True)\n",
    "        for word in s_x:\n",
    "            word_vec = Variable(embeddings[word].view(1, len(embeddings)))\n",
    "            word_y = Variable(torch.FloatTensor([int(word in s_y) / len(s_y)]))\n",
    "            \n",
    "            hidden_state, pred = model(word_vec, hidden_state)\n",
    "\n",
    "            ys = torch.cat((ys, word_y), 0)\n",
    "            preds = torch.cat((preds, pred), 0)\n",
    "        \n",
    "        \n",
    "        error = loss(preds, ys)\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch {} - Loss: {}\".format(epoch, round(float(error), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning seems a bit too easy but, anyway, let's check a training sample !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.04904607683420181\n",
      "forecast -0.02852250635623932\n",
      "in 0.08365827053785324\n",
      "Los 0.19558492302894592\n",
      "Angeles 0.27349403500556946\n",
      "please 0.07088281959295273\n"
     ]
    }
   ],
   "source": [
    "x = \"the forecast in Los Angeles please\"\n",
    "s_x = tokenizer(x)\n",
    "hidden_state = model.init_hidden()\n",
    "preds = []\n",
    "\n",
    "for word in s_x:\n",
    "    word_vec = Variable(embeddings[word].view(1, len(embeddings)))\n",
    "    hidden_state, pred = model(word_vec, hidden_state)\n",
    "    preds.append(float(pred))\n",
    "    \n",
    "    print(word, float(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 6 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f3b6ba828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are quite encouraging, now it's time to define a... let's say a *SCat Argument Determination Algorithm* to transform network output into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 6 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f9465b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "preds = Variable(torch.FloatTensor(preds))\n",
    "preds = F.softmax(preds)\n",
    "preds = [float(el) for el in preds]  # Back to list\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(len(preds)), preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the probabilities of the word being the unique argument, I believe that argument word are the top word that have a combined probability of, at maximum, 50%, not 1% more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Los', 'Angeles']\n"
     ]
    }
   ],
   "source": [
    "prob_sum = 0\n",
    "selected_words = []\n",
    "words = s_x.copy()\n",
    "\n",
    "while prob_sum < 0.5:\n",
    "    max_index = preds.index(max(preds))\n",
    "    prob_sum += preds.pop(max_index)\n",
    "    selected_words.append(words.pop(max_index))\n",
    "\n",
    "if prob_sum > 0.5:\n",
    "    del selected_words[-1]\n",
    "\n",
    "selected_words = sorted(selected_words, key=lambda x: s_x.index(x)) # Sort argument in the order of s_x\n",
    "print(selected_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It work just fine ! Tried with many other example and the result are quite robust for the size of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
